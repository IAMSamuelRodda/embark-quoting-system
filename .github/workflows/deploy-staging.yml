name: Deploy to Staging

on:
  # Deploy to staging when pushing tags with 'staging-' prefix
  # Example: git tag staging-v1.2.3 && git push origin staging-v1.2.3
  push:
    tags:
      - 'staging-v*'     # staging-v1.0.0, staging-v1.2.3, etc.
      - 'staging-*'       # staging-20250109, staging-feature-name, etc.
  # Allow manual triggers for debugging
  workflow_dispatch:

env:
  AWS_REGION: ap-southeast-2  # Sydney region (matches deployed infrastructure)
  ECR_REPOSITORY: embark-quoting-backend
  ECS_CLUSTER: embark-quoting-staging-cluster
  ECS_SERVICE: embark-quoting-staging-backend-service
  ECS_TASK_DEFINITION: embark-quoting-staging-backend
  CONTAINER_NAME: backend

jobs:
  deploy-backend:
    name: Deploy Backend to ECS
    runs-on: ubuntu-latest
    outputs:
      backend-url: ${{ steps.verify-backend.outputs.backend-url }}
    environment:
      name: staging
      url: https://staging-api.embark-quoting.com  # TODO: Update to your staging API URL

    permissions:
      id-token: write
      contents: read

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Verify staging tag
        run: |
          if [[ "${{ github.ref }}" == refs/tags/staging-* ]]; then
            echo "‚úÖ Tag check passed: Deploying from staging tag ${{ github.ref_name }}"
          else
            echo "‚ÑπÔ∏è Manual workflow dispatch detected"
          fi

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_TO_ASSUME }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2

      - name: Get latest image from ECR
        id: get-image
        run: |
          # Use 'latest' tag for main branch deployments
          IMAGE_TAG="latest"
          IMAGE_URI="${{ steps.login-ecr.outputs.registry }}/${{ env.ECR_REPOSITORY }}:${IMAGE_TAG}"
          echo "image-uri=${IMAGE_URI}" >> $GITHUB_OUTPUT
          echo "Deploying image: ${IMAGE_URI}"

      - name: Download task definition
        run: |
          aws ecs describe-task-definition \
            --task-definition ${{ env.ECS_TASK_DEFINITION }} \
            --query taskDefinition \
            > task-definition.json
        # TODO: Create initial ECS task definition in AWS

      - name: Update task definition with new image
        id: task-def
        uses: aws-actions/amazon-ecs-render-task-definition@v1
        with:
          task-definition: task-definition.json
          container-name: ${{ env.CONTAINER_NAME }}
          image: ${{ steps.get-image.outputs.image-uri }}

      - name: Deploy to Amazon ECS
        uses: aws-actions/amazon-ecs-deploy-task-definition@v1
        with:
          task-definition: ${{ steps.task-def.outputs.task-definition }}
          service: ${{ env.ECS_SERVICE }}
          cluster: ${{ env.ECS_CLUSTER }}
          wait-for-service-stability: true
          wait-for-minutes: 10

      - name: Verify deployment
        id: verify-backend
        run: |
          echo "Waiting for service to stabilize..."
          sleep 30

          # Cost-optimized architecture: No ALB, access ECS tasks directly via public IP
          echo "Getting ECS task public IP..."

          # Get task ARN from the service
          TASK_ARN=$(aws ecs list-tasks \
            --cluster ${{ env.ECS_CLUSTER }} \
            --service-name ${{ env.ECS_SERVICE }} \
            --region ${{ env.AWS_REGION }} \
            --query 'taskArns[0]' \
            --output text)

          if [ -z "$TASK_ARN" ] || [ "$TASK_ARN" = "None" ]; then
            echo "‚ùå Could not find running ECS task!"
            exit 1
          fi

          echo "Task ARN: $TASK_ARN"

          # Get task details to extract public IP
          TASK_IP=$(aws ecs describe-tasks \
            --cluster ${{ env.ECS_CLUSTER }} \
            --tasks $TASK_ARN \
            --region ${{ env.AWS_REGION }} \
            --query 'tasks[0].attachments[0].details[?name==`networkInterfaceId`].value' \
            --output text | xargs -I {} aws ec2 describe-network-interfaces \
            --network-interface-ids {} \
            --region ${{ env.AWS_REGION }} \
            --query 'NetworkInterfaces[0].Association.PublicIp' \
            --output text)

          if [ -z "$TASK_IP" ] || [ "$TASK_IP" = "None" ]; then
            echo "‚ùå Could not retrieve task public IP!"
            exit 1
          fi

          echo "‚úÖ ECS Task Public IP: $TASK_IP"

          # Backend is accessed directly via HTTP (no ALB, no CloudFront)
          # Frontend (CloudFront HTTPS) will call backend (HTTP) - creates mixed content warning
          BACKEND_URL="http://${TASK_IP}:3000"
          echo "backend-url=${BACKEND_URL}" >> $GITHUB_OUTPUT
          HEALTH_URL="${BACKEND_URL}/health"

          echo "Running health check on ${HEALTH_URL}"

          # Retry health check with backoff (task may still be starting)
          MAX_RETRIES=6
          RETRY_COUNT=0
          while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
            response=$(curl -s -o /dev/null -w "%{http_code}" $HEALTH_URL)

            if [ "$response" = "200" ]; then
              echo "‚úÖ Deployment successful! Health check passed."
              echo "Backend is accessible at: $HEALTH_URL"
              echo ""
              echo "‚ö†Ô∏è  NOTE: Backend uses direct IP access (cost optimization)"
              echo "   IP will change on every ECS task restart!"
              echo "   STAGING_API_URL secret will be updated automatically."
              break
            else
              RETRY_COUNT=$((RETRY_COUNT + 1))
              if [ $RETRY_COUNT -lt $MAX_RETRIES ]; then
                echo "‚è≥ Health check returned $response, retrying in 10s... (attempt $RETRY_COUNT/$MAX_RETRIES)"
                sleep 10
              else
                echo "‚ùå Deployment failed! Health check returned: $response after $MAX_RETRIES attempts"
                exit 1
              fi
            fi
          done

      - name: Update STAGING_API_URL secret
        env:
          GH_TOKEN: ${{ secrets.GH_PAT }}
        run: |
          echo "üìù Updating STAGING_API_URL secret with current backend IP..."
          gh secret set STAGING_API_URL \
            --body "${{ steps.verify-backend.outputs.backend-url }}" \
            --repo ${{ github.repository }}
          echo "‚úÖ STAGING_API_URL updated: ${{ steps.verify-backend.outputs.backend-url }}"

  deploy-frontend:
    name: Deploy Frontend to S3/CloudFront
    runs-on: ubuntu-latest
    environment:
      name: staging
      url: https://staging.embark-quoting.com  # TODO: Update to your staging frontend URL

    permissions:
      id-token: write
      contents: read

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Verify staging tag
        run: |
          if [[ "${{ github.ref }}" == refs/tags/staging-* ]]; then
            echo "‚úÖ Tag check passed: Deploying from staging tag ${{ github.ref_name }}"
          else
            echo "‚ÑπÔ∏è Manual workflow dispatch detected"
          fi

      - name: Setup Node.js 20
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: frontend/package-lock.json

      - name: Install dependencies
        working-directory: ./frontend
        run: npm ci

      - name: Build frontend for staging
        working-directory: ./frontend
        run: npm run build
        env:
          NODE_ENV: production
          VITE_API_URL: ${{ secrets.STAGING_API_URL }}
          VITE_COGNITO_USER_POOL_ID: ${{ secrets.STAGING_COGNITO_USER_POOL_ID }}
          VITE_COGNITO_CLIENT_ID: ${{ secrets.STAGING_COGNITO_CLIENT_ID }}
          VITE_COGNITO_REGION: ${{ env.AWS_REGION }}

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_TO_ASSUME }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Deploy to S3
        run: |
          aws s3 sync ./frontend/dist/ s3://${{ secrets.STAGING_S3_BUCKET }}/ \
            --delete \
            --cache-control "public, max-age=31536000, immutable" \
            --exclude "index.html" \
            --exclude "service-worker.js"

          # Cache index.html and service-worker.js for shorter time
          aws s3 cp ./frontend/dist/index.html s3://${{ secrets.STAGING_S3_BUCKET }}/index.html \
            --cache-control "public, max-age=0, must-revalidate"

          if [ -f ./frontend/dist/service-worker.js ]; then
            aws s3 cp ./frontend/dist/service-worker.js s3://${{ secrets.STAGING_S3_BUCKET }}/service-worker.js \
              --cache-control "public, max-age=0, must-revalidate"
          fi
        # TODO: Create S3 bucket for staging frontend

      - name: Invalidate CloudFront cache
        run: |
          aws cloudfront create-invalidation \
            --distribution-id ${{ secrets.STAGING_CLOUDFRONT_ID }} \
            --paths "/*"
        # TODO: Create CloudFront distribution for staging

      - name: Verify frontend deployment
        run: |
          echo "Waiting for CloudFront invalidation..."
          sleep 30

          # Check if index.html is accessible
          response=$(curl -s -o /dev/null -w "%{http_code}" ${{ secrets.STAGING_FRONTEND_URL }})

          if [ "$response" = "200" ]; then
            echo "‚úÖ Frontend deployment successful!"
          else
            echo "‚ùå Frontend deployment failed! Response: $response"
            exit 1
          fi

  # Amazon-Style Testing: Comprehensive E2E tests on staging
  # Production gets minimal smoke tests only (see deploy-prod.yml)
  # NOTE: E2E tests are INFORMATIONAL - deployment success is independent of test results
  # This allows deploying fixes that E2E tests verify, preventing chicken-and-egg deployment blocks
  e2e-tests:
    name: Comprehensive E2E Tests (Staging)
    if: ${{ !cancelled() }}
    needs: [deploy-backend, deploy-frontend]
    continue-on-error: true  # Don't block deployment success if E2E tests fail
    uses: ./.github/workflows/e2e-tests.yml
    with:
      # Pass dynamic backend URL as input (from deploy-backend job output)
      api-url: ${{ needs.deploy-backend.outputs.backend-url }}
      environment: staging
      # Run ALL E2E tests on staging (comprehensive validation)
      test-pattern: 'e2e/**/*.spec.ts'
    secrets:
      # Pass frontend URL through secrets (cannot use secrets.* in with: section)
      base-url-secret: ${{ secrets.STAGING_FRONTEND_URL }}
      test-user-email: ${{ secrets.E2E_TEST_USER_EMAIL }}
      test-user-password: ${{ secrets.E2E_TEST_USER_PASSWORD }}

  # Deployment Summary - Always succeeds if core deployment jobs succeed
  # This ensures workflow shows GREEN even if optional verification jobs (E2E, Lighthouse) fail
  deployment-summary:
    name: Deployment Summary
    runs-on: ubuntu-latest
    if: ${{ !cancelled() }}
    needs: [deploy-backend, deploy-frontend]

    steps:
      - name: Deployment Status
        run: |
          echo "## üöÄ Staging Deployment Complete"
          echo ""
          echo "‚úÖ **Backend Deployed**: ${{ needs.deploy-backend.outputs.backend-url }}"
          echo "‚úÖ **Frontend Deployed**: ${{ secrets.STAGING_FRONTEND_URL }}"
          echo ""
          echo "### Verification Jobs"
          echo "- E2E Tests: Run separately (non-blocking)"
          echo "- Lighthouse Audit: Run separately (non-blocking)"
          echo ""
          echo "Check individual job results for verification status."

  lighthouse:
    name: Lighthouse Performance Audit
    runs-on: ubuntu-latest
    if: ${{ !cancelled() }}
    needs: [deploy-frontend]
    continue-on-error: true  # Don't block deployment success if audit fails

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Run Lighthouse CI
        uses: treosh/lighthouse-ci-action@v10
        with:
          urls: |
            ${{ secrets.STAGING_FRONTEND_URL }}
            ${{ secrets.STAGING_FRONTEND_URL }}/quotes
          temporaryPublicStorage: true

      - name: Check Lighthouse scores
        run: |
          echo "Lighthouse audit complete. Check artifacts for detailed report."
          echo "Minimum required scores:"
          echo "  - Performance: 90"
          echo "  - Accessibility: 90"
          echo "  - Best Practices: 90"
          echo "  - SEO: 90"
        # TODO: Add automated score enforcement
